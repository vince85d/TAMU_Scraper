name: Daily Job Scraper

on:
  schedule:
    # Run daily at 9:00 AM UTC (adjust timezone as needed)
    - cron: '0 9 * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4
        
    - name: Install Selenium
      run: pip install selenium
        
    - name: Run job scraper
      env:
        FROM_EMAIL: ${{ secrets.FROM_EMAIL }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        TO_EMAIL: ${{ secrets.TO_EMAIL }}
        SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
        SMTP_PORT: ${{ secrets.SMTP_PORT }}
      run: python job_scraper.py
      
    - name: Upload logs and state
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: |
          sent_jobs.json
          *.log
        retention-days: 30
        
    - name: Commit updated sent_jobs.json
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add sent_jobs.json
        git diff --staged --quiet || git commit -m "Update sent jobs list [automated]"
        git push
      continue-on-error: true
